# ç¼“å­˜æ—¥å¿—è®°å½•æŒ‡å—

> Redis ç¼“å­˜æœºåˆ¶çš„ç»“æ„åŒ–æ—¥å¿—è®°å½•åŠŸèƒ½ä½¿ç”¨æŒ‡å—ï¼ŒåŒ…å«æ—¥å¿—æ ¼å¼ã€åˆ†ææ–¹æ³•å’Œç›‘æ§å‘Šè­¦

## æ¦‚è¿°

Redis ç¼“å­˜æœºåˆ¶æä¾›äº†å®Œæ•´çš„ç»“æ„åŒ–æ—¥å¿—è®°å½•åŠŸèƒ½ï¼Œä½¿ç”¨ JSON æ ¼å¼è®°å½•æ‰€æœ‰ç¼“å­˜æ“ä½œã€é™çº§äº‹ä»¶å’Œç¼“å­˜çŠ¶æ€å˜åŒ–ã€‚è¿™äº›æ—¥å¿—å¯¹äºç›‘æ§ã€è°ƒè¯•å’Œæ€§èƒ½åˆ†æè‡³å…³é‡è¦ã€‚

## å¿«é€Ÿå¼€å§‹

å¦‚æœä½ æƒ³å¿«é€Ÿäº†è§£ç¼“å­˜æ—¥å¿—è®°å½•åŠŸèƒ½ï¼Œå¯ä»¥è¿è¡Œæˆ‘ä»¬æä¾›çš„æ¼”ç¤ºç¤ºä¾‹ï¼š

```bash
# æ¿€æ´» Conda ç¯å¢ƒ
conda activate mai_notebook

# è¿è¡Œç¼“å­˜æ—¥å¿—æ¼”ç¤º
python examples/cache_logging_demo.py
```

è¯¥ç¤ºä¾‹ä¼šæ¼”ç¤ºï¼š
- ç¼“å­˜çš„åŸºæœ¬æ“ä½œå’Œæ—¥å¿—è¾“å‡º
- ç¼“å­˜é™çº§åœºæ™¯ï¼ˆRedis æ•…éšœã€ç¼“å­˜ç¦ç”¨ï¼‰
- æ—¥å¿—åˆ†ææ–¹æ³•å’Œå‘½ä»¤

è¯¦ç»†è¯´æ˜è¯·å‚è€ƒï¼š[examples/README.md](../../examples/README.md)

## æ—¥å¿—æ ¼å¼

æ‰€æœ‰ç¼“å­˜æ—¥å¿—éƒ½é‡‡ç”¨ JSON æ ¼å¼ï¼ŒåŒ…å«ä»¥ä¸‹æ ‡å‡†å­—æ®µï¼š

```json
{
    "timestamp": "2024-01-15T10:30:45.123Z",
    "level": "INFO",
    "operation": "cache_get",
    "source": "CacheManager",
    ...
}
```

### æ ‡å‡†å­—æ®µè¯´æ˜

- `timestamp`: ISO 8601 æ ¼å¼çš„ UTC æ—¶é—´æˆ³
- `level`: æ—¥å¿—çº§åˆ«ï¼ˆINFO, WARNING, ERRORï¼‰
- `operation`: æ“ä½œç±»å‹ï¼ˆcache_get, cache_set, cache_invalidate, cache_degradation, cache_disabled, cache_enabledï¼‰
- `source`: æ—¥å¿—æ¥æºï¼ˆå›ºå®šä¸º "CacheManager"ï¼‰

## æ—¥å¿—ç±»å‹

### 1. ç¼“å­˜è·å–æ—¥å¿— (cache_get)

è®°å½•ç¼“å­˜è¯»å–æ“ä½œçš„ç»“æœã€‚

**æˆåŠŸç¤ºä¾‹ï¼ˆç¼“å­˜å‘½ä¸­ï¼‰ï¼š**
```json
{
    "timestamp": "2024-01-15T10:30:45.123Z",
    "level": "INFO",
    "operation": "cache_get",
    "key": "maimnp:user:123",
    "hit": true,
    "latency_ms": 5.2,
    "degraded": false,
    "source": "CacheManager"
}
```

**æœªå‘½ä¸­ç¤ºä¾‹ï¼š**
```json
{
    "timestamp": "2024-01-15T10:30:46.456Z",
    "level": "INFO",
    "operation": "cache_get",
    "key": "maimnp:user:456",
    "hit": false,
    "latency_ms": 3.1,
    "degraded": false,
    "source": "CacheManager"
}
```

**é™çº§ç¤ºä¾‹ï¼ˆRedis æ•…éšœï¼‰ï¼š**
```json
{
    "timestamp": "2024-01-15T10:30:47.789Z",
    "level": "WARNING",
    "operation": "cache_get",
    "key": "maimnp:user:789",
    "hit": false,
    "latency_ms": 10.5,
    "degraded": true,
    "error": "Connection refused",
    "source": "CacheManager"
}
```

### 2. ç¼“å­˜è®¾ç½®æ—¥å¿— (cache_set)

è®°å½•ç¼“å­˜å†™å…¥æ“ä½œçš„ç»“æœã€‚

**æˆåŠŸç¤ºä¾‹ï¼š**
```json
{
    "timestamp": "2024-01-15T10:31:00.123Z",
    "level": "INFO",
    "operation": "cache_set",
    "key": "maimnp:user:123",
    "success": true,
    "ttl": 3600,
    "latency_ms": 2.5,
    "degraded": false,
    "source": "CacheManager"
}
```

**å¤±è´¥ç¤ºä¾‹ï¼š**
```json
{
    "timestamp": "2024-01-15T10:31:01.456Z",
    "level": "WARNING",
    "operation": "cache_set",
    "key": "maimnp:user:456",
    "success": false,
    "ttl": 3600,
    "latency_ms": 8.3,
    "degraded": false,
    "error": "Serialization error: Object of type datetime is not JSON serializable",
    "source": "CacheManager"
}
```

**é™çº§ç¤ºä¾‹ï¼ˆç¼“å­˜ç¦ç”¨ï¼‰ï¼š**
```json
{
    "timestamp": "2024-01-15T10:31:02.789Z",
    "level": "INFO",
    "operation": "cache_set",
    "key": "maimnp:user:789",
    "success": true,
    "ttl": 3600,
    "degraded": true,
    "source": "CacheManager"
}
```

### 3. ç¼“å­˜å¤±æ•ˆæ—¥å¿— (cache_invalidate)

è®°å½•ç¼“å­˜åˆ é™¤æ“ä½œã€‚

**å•é”®å¤±æ•ˆç¤ºä¾‹ï¼š**
```json
{
    "timestamp": "2024-01-15T10:32:00.123Z",
    "level": "INFO",
    "operation": "cache_invalidate",
    "key": "maimnp:user:123",
    "success": true,
    "degraded": false,
    "source": "CacheManager"
}
```

**æ‰¹é‡å¤±æ•ˆç¤ºä¾‹ï¼š**
```json
{
    "timestamp": "2024-01-15T10:32:01.456Z",
    "level": "INFO",
    "operation": "cache_invalidate",
    "pattern": "maimnp:user:*",
    "count": 10,
    "success": true,
    "degraded": false,
    "source": "CacheManager"
}
```

**å¤±è´¥ç¤ºä¾‹ï¼š**
```json
{
    "timestamp": "2024-01-15T10:32:02.789Z",
    "level": "WARNING",
    "operation": "cache_invalidate",
    "key": "maimnp:user:456",
    "success": false,
    "degraded": false,
    "error": "Connection timeout",
    "source": "CacheManager"
}
```

### 4. ç¼“å­˜é™çº§æ—¥å¿— (cache_degradation)

è®°å½•ç¼“å­˜é™çº§äº‹ä»¶ï¼ŒåŒ…å«é™çº§åŸå› å’Œé”™è¯¯ä¿¡æ¯ã€‚

**Redis è¿æ¥å¤±è´¥ç¤ºä¾‹ï¼š**
```json
{
    "timestamp": "2024-01-15T10:33:00.123Z",
    "level": "WARNING",
    "operation": "cache_degradation",
    "reason": "redis_connection_failed",
    "original_operation": "get_cached",
    "key": "maimnp:user:123",
    "error": "Connection refused: [Errno 61] Connection refused",
    "fallback": "fetch_func",
    "source": "CacheManager"
}
```

**ç¼“å­˜ç¦ç”¨ç¤ºä¾‹ï¼š**
```json
{
    "timestamp": "2024-01-15T10:33:01.456Z",
    "level": "WARNING",
    "operation": "cache_degradation",
    "reason": "cache_disabled",
    "original_operation": "get_cached",
    "key": "maimnp:knowledge:456",
    "fallback": "fetch_func",
    "source": "CacheManager"
}
```

### 5. ç¼“å­˜çŠ¶æ€æ—¥å¿—

**ç¼“å­˜ç¦ç”¨æ—¥å¿— (cache_disabled)ï¼š**
```json
{
    "timestamp": "2024-01-15T10:00:00.000Z",
    "level": "INFO",
    "operation": "cache_disabled",
    "reason": "config_enabled_false",
    "source": "CacheManager"
}
```

**ç¼“å­˜å¯ç”¨æ—¥å¿— (cache_enabled)ï¼š**
```json
{
    "timestamp": "2024-01-15T10:00:01.000Z",
    "level": "INFO",
    "operation": "cache_enabled",
    "source": "CacheManager"
}
```

## æ—¥å¿—é…ç½®

### é…ç½®ç»“æ„åŒ–æ—¥å¿—è¾“å‡º

åœ¨åº”ç”¨å¯åŠ¨æ—¶é…ç½®æ—¥å¿—æ ¼å¼ï¼š

```python
import logging
import json

# é…ç½® JSON æ ¼å¼çš„æ—¥å¿—å¤„ç†å™¨
class JsonFormatter(logging.Formatter):
    def format(self, record):
        # å¦‚æœæ—¥å¿—æ¶ˆæ¯å·²ç»æ˜¯ JSON æ ¼å¼ï¼Œç›´æ¥è¿”å›
        try:
            json.loads(record.getMessage())
            return record.getMessage()
        except (json.JSONDecodeError, ValueError):
            # å¦åˆ™ä½¿ç”¨æ ‡å‡†æ ¼å¼
            return super().format(record)

# é…ç½®æ—¥å¿—
handler = logging.StreamHandler()
handler.setFormatter(JsonFormatter())

logger = logging.getLogger("app.core.cache")
logger.addHandler(handler)
logger.setLevel(logging.INFO)
```

### é…ç½®æ—¥å¿—æ–‡ä»¶è¾“å‡º

å°†æ—¥å¿—è¾“å‡ºåˆ°æ–‡ä»¶ï¼š

```python
import logging
from logging.handlers import RotatingFileHandler

# åˆ›å»ºæ—¥å¿—ç›®å½•
import os
os.makedirs("logs", exist_ok=True)

# é…ç½®æ–‡ä»¶å¤„ç†å™¨ï¼ˆè‡ªåŠ¨è½®è½¬ï¼‰
file_handler = RotatingFileHandler(
    "logs/cache.log",
    maxBytes=10 * 1024 * 1024,  # 10MB
    backupCount=5
)
file_handler.setFormatter(JsonFormatter())

logger = logging.getLogger("app.core.cache")
logger.addHandler(file_handler)
logger.setLevel(logging.INFO)
```

## æ—¥å¿—åˆ†æ

### ä½¿ç”¨ jq åˆ†ææ—¥å¿—

```bash
# æŸ¥çœ‹æ‰€æœ‰ç¼“å­˜é™çº§äº‹ä»¶
cat logs/cache.log | jq 'select(.operation == "cache_degradation")'

# ç»Ÿè®¡ç¼“å­˜å‘½ä¸­ç‡
cat logs/cache.log | jq 'select(.operation == "cache_get") | .hit' | \
  awk '{hit+=$1; total++} END {print "å‘½ä¸­ç‡:", hit/total*100"%"}'

# æŸ¥çœ‹å¹³å‡å»¶è¿Ÿ
cat logs/cache.log | jq 'select(.latency_ms) | .latency_ms' | \
  awk '{sum+=$1; count++} END {print "å¹³å‡å»¶è¿Ÿ:", sum/count, "ms"}'

# æŸ¥çœ‹é™çº§åŸå› ç»Ÿè®¡
cat logs/cache.log | jq -r 'select(.operation == "cache_degradation") | .reason' | \
  sort | uniq -c | sort -rn

# æŸ¥çœ‹é”™è¯¯æ—¥å¿—
cat logs/cache.log | jq 'select(.level == "WARNING" or .level == "ERROR")'
```

### ä½¿ç”¨ Python åˆ†ææ—¥å¿—

```python
import json
from collections import Counter

def analyze_cache_logs(log_file):
    """åˆ†æç¼“å­˜æ—¥å¿—æ–‡ä»¶"""
    hits = 0
    misses = 0
    degradations = Counter()
    latencies = []
    
    with open(log_file, 'r') as f:
        for line in f:
            try:
                log = json.loads(line)
                
                # ç»Ÿè®¡ç¼“å­˜å‘½ä¸­ç‡
                if log.get('operation') == 'cache_get':
                    if log.get('hit'):
                        hits += 1
                    else:
                        misses += 1
                    
                    # æ”¶é›†å»¶è¿Ÿæ•°æ®
                    if 'latency_ms' in log:
                        latencies.append(log['latency_ms'])
                
                # ç»Ÿè®¡é™çº§åŸå› 
                if log.get('operation') == 'cache_degradation':
                    reason = log.get('reason', 'unknown')
                    degradations[reason] += 1
            
            except json.JSONDecodeError:
                continue
    
    # è¾“å‡ºç»Ÿè®¡ç»“æœ
    total = hits + misses
    if total > 0:
        print(f"ç¼“å­˜å‘½ä¸­ç‡: {hits/total*100:.2f}%")
        print(f"æ€»è¯·æ±‚æ•°: {total}")
        print(f"å‘½ä¸­æ¬¡æ•°: {hits}")
        print(f"æœªå‘½ä¸­æ¬¡æ•°: {misses}")
    
    if latencies:
        avg_latency = sum(latencies) / len(latencies)
        print(f"\nå¹³å‡å»¶è¿Ÿ: {avg_latency:.2f} ms")
        print(f"æœ€å°å»¶è¿Ÿ: {min(latencies):.2f} ms")
        print(f"æœ€å¤§å»¶è¿Ÿ: {max(latencies):.2f} ms")
    
    if degradations:
        print("\né™çº§äº‹ä»¶ç»Ÿè®¡:")
        for reason, count in degradations.most_common():
            print(f"  {reason}: {count} æ¬¡")

# ä½¿ç”¨ç¤ºä¾‹
analyze_cache_logs("logs/cache.log")
```

## ç›‘æ§å‘Šè­¦

### åŸºäºæ—¥å¿—çš„å‘Šè­¦è§„åˆ™

1. **ç¼“å­˜å‘½ä¸­ç‡ä½**
   - æ¡ä»¶ï¼šè¿ç»­ 5 åˆ†é’Ÿå‘½ä¸­ç‡ < 70%
   - æ—¥å¿—è¿‡æ»¤ï¼š`operation == "cache_get" and hit == false`

2. **é¢‘ç¹é™çº§**
   - æ¡ä»¶ï¼šæ¯åˆ†é’Ÿé™çº§æ¬¡æ•° > 10
   - æ—¥å¿—è¿‡æ»¤ï¼š`operation == "cache_degradation"`

3. **ç¼“å­˜æ“ä½œå»¶è¿Ÿé«˜**
   - æ¡ä»¶ï¼šP99 å»¶è¿Ÿ > 100ms
   - æ—¥å¿—è¿‡æ»¤ï¼š`latency_ms > 100`

4. **ç¼“å­˜å†™å…¥å¤±è´¥**
   - æ¡ä»¶ï¼šä»»ä½•ç¼“å­˜å†™å…¥å¤±è´¥
   - æ—¥å¿—è¿‡æ»¤ï¼š`operation == "cache_set" and success == false`

### é›†æˆåˆ°ç›‘æ§ç³»ç»Ÿ

**Elasticsearch + Kibanaï¼š**
```bash
# ä½¿ç”¨ Filebeat æ”¶é›†æ—¥å¿—
filebeat.inputs:
- type: log
  enabled: true
  paths:
    - /path/to/logs/cache.log
  json.keys_under_root: true
  json.add_error_key: true

output.elasticsearch:
  hosts: ["localhost:9200"]
  index: "cache-logs-%{+yyyy.MM.dd}"
```

**Prometheus + Grafanaï¼š**
```python
# ä»æ—¥å¿—ä¸­æå–æŒ‡æ ‡
from prometheus_client import Counter, Histogram

cache_operations = Counter(
    'cache_operations_total',
    'ç¼“å­˜æ“ä½œæ€»æ•°',
    ['operation', 'status']
)

cache_latency = Histogram(
    'cache_operation_latency_seconds',
    'ç¼“å­˜æ“ä½œå»¶è¿Ÿ',
    ['operation']
)

# åœ¨æ—¥å¿—è®°å½•æ—¶æ›´æ–°æŒ‡æ ‡
def log_and_metric(operation, status, latency_ms=None):
    cache_operations.labels(operation=operation, status=status).inc()
    if latency_ms:
        cache_latency.labels(operation=operation).observe(latency_ms / 1000)
```

## æœ€ä½³å®è·µ

1. **æ—¥å¿—çº§åˆ«é€‰æ‹©**
   - INFO: æ­£å¸¸çš„ç¼“å­˜æ“ä½œï¼ˆå‘½ä¸­ã€æœªå‘½ä¸­ã€è®¾ç½®æˆåŠŸï¼‰
   - WARNING: é™çº§äº‹ä»¶ã€æ“ä½œå¤±è´¥ã€é”™è¯¯æ¢å¤
   - ERROR: ä¸¥é‡é”™è¯¯ï¼ˆä¸åº”è¯¥å‡ºç°åœ¨æ­£å¸¸é™çº§åœºæ™¯ä¸­ï¼‰

2. **æ—¥å¿—ä¿ç•™ç­–ç•¥**
   - å¼€å‘ç¯å¢ƒï¼šä¿ç•™ 7 å¤©
   - æµ‹è¯•ç¯å¢ƒï¼šä¿ç•™ 14 å¤©
   - ç”Ÿäº§ç¯å¢ƒï¼šä¿ç•™ 30 å¤©

3. **æ€§èƒ½è€ƒè™‘**
   - ä½¿ç”¨å¼‚æ­¥æ—¥å¿—å†™å…¥é¿å…é˜»å¡
   - é…ç½®åˆé€‚çš„æ—¥å¿—è½®è½¬ç­–ç•¥
   - é¿å…åœ¨é«˜é¢‘æ“ä½œä¸­è®°å½•è¿‡å¤šè¯¦ç»†ä¿¡æ¯

4. **éšç§ä¿æŠ¤**
   - ä¸è¦åœ¨æ—¥å¿—ä¸­è®°å½•æ•æ„Ÿæ•°æ®ï¼ˆå¯†ç ã€ä»¤ç‰Œç­‰ï¼‰
   - å¯¹ç”¨æˆ· ID ç­‰ä¿¡æ¯è¿›è¡Œè„±æ•å¤„ç†
   - éµå®ˆæ•°æ®ä¿æŠ¤æ³•è§„ï¼ˆGDPRã€CCPA ç­‰ï¼‰

## æ•…éšœæ’æŸ¥

### å¸¸è§é—®é¢˜è¯Šæ–­

**é—®é¢˜ 1ï¼šç¼“å­˜å‘½ä¸­ç‡ä½**
```bash
# æŸ¥çœ‹æœªå‘½ä¸­çš„é”®æ¨¡å¼
cat logs/cache.log | jq -r 'select(.operation == "cache_get" and .hit == false) | .key' | \
  sed 's/:[^:]*$//' | sort | uniq -c | sort -rn
```

**é—®é¢˜ 2ï¼šé¢‘ç¹é™çº§**
```bash
# æŸ¥çœ‹é™çº§åŸå› å’Œé¢‘ç‡
cat logs/cache.log | jq -r 'select(.operation == "cache_degradation") | 
  "\(.timestamp) \(.reason) \(.error)"'
```

**é—®é¢˜ 3ï¼šå»¶è¿Ÿå¼‚å¸¸**
```bash
# æŸ¥çœ‹é«˜å»¶è¿Ÿæ“ä½œ
cat logs/cache.log | jq 'select(.latency_ms > 50) | 
  {timestamp, operation, key, latency_ms}'
```

## ç›¸å…³æ–‡æ¡£

- [ç¼“å­˜ç³»ç»Ÿé…ç½®æŒ‡å—](./ç¼“å­˜ç³»ç»Ÿé…ç½®æŒ‡å—.md)
- [ç¼“å­˜ä¸­é—´ä»¶ä½¿ç”¨æŒ‡å—](./ç¼“å­˜ä¸­é—´ä»¶ä½¿ç”¨æŒ‡å—.md)

---

**æ–‡æ¡£ä¿¡æ¯**

| é¡¹ç›® | å†…å®¹ |
|------|------|
| åˆ›å»ºæ—¥æœŸ | 2026-02-23 |
| æœ€åæ›´æ–° | 2026-02-23 |
| ç»´æŠ¤è€… | CorrectPath, A-Dawn, cuckoo711 |
| çŠ¶æ€ | ğŸ“ å‚è€ƒæ–‡æ¡£ |
